{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시시닥거리와 개발노트는 여기에, 밑에는 깔끔하고 extensible한 코드베이스 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7월 16일 쓰다가 무슨일인지 멈췄다, 8월 13일 재게."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. 목적: 코드베이스 깔끔화**\n",
    "\n",
    "Live Braille. 2-3일을 쏟아부은 재밌는 프로젝트였지만, 아쉬운 점은 코드베이스가 스파게티화되어 더이상의 수정이 힘들어진 것. 버전업하며 최적화를 해결하고 효율적인 구조를 적용해 추후 기능추가를 수월하게, 또 다른 프로젝트에 융합가능한 모듈로서 매듭을 짓고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. On Use of PaddleOCR.**\n",
    "\n",
    "인식률과 런타임이 훌륭한 scene text detection 알고리즘은 PaddleOCR과 EasyOCR이 있다. 이중 PaddleOCR이 넘사벽으로 (6배가량) 빠르지만, 실행환경 셋업이 복잡한 단점을 가졌다. 정확히 말하자면, 무슨 이유인지, 공식 설치로는 버그가 있어 실행이 안되고, Conda로는 오래되고 인기없는 formulae에 의존해야 한다. Paddle이라는 중국발 딥러닝 프레임워크를 사용해야 하는것이 사실은 조금 싫지만, 사실 deployment를 고려한다면 내가 이 프레임워크를 배우고 딥러닝 에코시스템을 배우는건 좋은 점이기에, 후에 더 중요한 이유가 나오지 않는 한 PaddleOCR을 사용할 계획이다. 더 생각을 하기엔 시간이 아깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ 두시간 가량 삽질한 결과, 전체적인 그림을 이해하기 시작했다. Paddle은 훈련부터 Deployment를 모두 포함한 풀스택 DL 프레임워크고, 당연히 TRT와 같은 런타임 최적화를 포함한다. 다만 PaddleOCR도 준 production-level 급의 라이브러리로, 이미 상당히 최적화되어있다. [PaddleOCR의 TRT 성능 상승폭은 25% 가량이다.](https://github.com/PaddlePaddle/PaddleOCR/issues/6663#issuecomment-1162998567) `paddlepaddle-gpu` 대신 `paddle inference` (link in Pocket) 를 깔면 TRT를 쓸 수 있지만 Paddle측 유지보수가 똥이라 Docker를 배우거나, TensorRT 및 엔비디아 컴퓨터 툴킷에 대해 (특히 버전컨트롤) 공부해야만 쓸 수 있겠다. Docker는 local file immutability, camera stream 등의 문제로 생각치 않는 중이다. 이미 Paddle은 EasyOCR+TensorRT보다 빠르기 때문에, 현재 알고리즘으로 만족하고 개발 후 칼만도 배워볼겸, SORT 기반 최적화가 가능한지 생각하면 되겠다. 원론적으로 생각해보면, 매초 60번씩 OCR을 돌린다는건 넌센스고, 기억에 의존하는 것이 맞다. 사람도 그렇게 작동할 것이고."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA/Conda/Paddle로 삽질하며 느낀 점들을 여기 적어보자. 이전의 PaddleOCR hang 문제는 내가 CUDA 버전에 맞지 않는 Paddlepaddle-gpu를 설치해서 그런 것이였다. 단순 PyPi/Conda 설치가 아닌, Paddle 웹사이트에 들어가니 PyTorch와 비슷하게 버전에 맞춘 custom wheel URL로 pip 설치 커맨드를 주더라. 허허. 엔비디아 이놈들때문에 여럿 고생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. On Optimization.**\n",
    "\n",
    "현재 최적화 아이디어는 역시나 칼만기반이 있다. OrCAM과 비슷한 기능을 구현하려면 environmental memory 시스템 또한 필요하다. 하지만 나는 앞으로 TensorRT를 배울 생각이며, Paddle에 TensorRT까지 더하면 속도가 무척 빠르기 때문에 지금으로썬 최적화를 보류하기로 했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. SORT to Solve Temporal Misrecognition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import dearpygui.dearpygui as dpg\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = [1400, 800]\n",
    "viz_res = tuple([400, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Subcomponents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug = True\n",
    "debug = False\n",
    "test_name = 'sign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b7150088e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if debug: \n",
    "    img_raw = cv2.cvtColor(cv2.imread('./test_images/test_{}.jpg'.format(test_name)), cv2.COLOR_BGR2RGB)\n",
    "else:\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    _, img_raw = cam.read()\n",
    "\n",
    "img = cv2.resize(img_raw, viz_res, interpolation=cv2.INTER_AREA)\n",
    "# img_rgba = rgba(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdpg2(img):\n",
    "    return img.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1A. Scene Text Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "# paddle = PaddleOCR(lang=\"en\", debug=False, show_log=False)\n",
    "paddle = PaddleOCR(lang=\"en\", debug=False, show_log=False, use_angle_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "result = paddle.ocr(img, cls=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why does this fucking work? ...\n",
    "# refactoring needed soon -> highlight() and select() functions\n",
    "\n",
    "def process(img, texts, sf=1):\n",
    "    img = img.copy()\n",
    "\n",
    "    # selection\n",
    "    min_dist = 200\n",
    "    selection = None\n",
    "    center = (int(img.shape[1]/2), int(img.shape[0]/2))\n",
    "\n",
    "\n",
    "    # highlight mask\n",
    "    weak = np.zeros(shape=img.shape)\n",
    "    strong = np.zeros(shape=img.shape)\n",
    "\n",
    "    # iterate through each text\n",
    "    for i, r in enumerate(texts): \n",
    "        # print(r)\n",
    "\n",
    "        # points\n",
    "        pt1 = [int(n*sf) for n in r[0][0]]\n",
    "        pt2 = [int(n*sf) for n in r[0][2]]\n",
    "\n",
    "        # add highlight\n",
    "        try: weak = add_mask(weak, pt1, pt2)\n",
    "        except Exception: print('highlight error')\n",
    "\n",
    "        # select\n",
    "        dist = distance([pt1, pt2], center)\n",
    "        if dist < min_dist: \n",
    "            min_dist = dist\n",
    "            selection = r\n",
    "\n",
    "    # selected text\n",
    "    # print('Selected text: ', selection)\n",
    "    if selection:\n",
    "        pt1, pt2 = [int(n*sf) for n in selection[0][0]], [int(n*sf) for n in selection[0][2]]\n",
    "        pt1, pt2 = tuple(pt1), tuple(pt2) # OpenCV's rectangle doesn't like coordinates given in list\n",
    "        strong = add_mask(strong, pt1, pt2)\n",
    "        img = cv2.rectangle(img, pt1, pt2, (255,255,255), 15) # outline\n",
    "\n",
    "    # visualization\n",
    "    img = cv2.rectangle(img, center, center, (0,50,0), 20) # center\n",
    "    highlighted = apply_highlight(img, weak, strong)\n",
    "\n",
    "    return highlighted, selection\n",
    "    # return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, sel = process(img, result)\n",
    "# pre-pygame-processing\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "# frame = np.rot90(np.fliplr(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b72550f8b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B. **Hand Pose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(model_complexity=0, max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "# process\n",
    "mp_results = hands.process(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize visualization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hands(mp_results, img):\n",
    "    img = img.copy()\n",
    "    landmarks = mp_results.multi_hand_landmarks\n",
    "    if landmarks:\n",
    "        for landmark in landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                img, landmark, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # print(landmarks)\n",
    "    return img\n",
    "\n",
    "# plt.imshow(visualize_hands(mp_results, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1C. **Hand Gesture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pose based RNN, debouncing, action-based vs. state-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state가 쉬우니까, continuous pointing based 느낌으로 먼저 ㄱㄱ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a big TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX, quantization, 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global - local kalman filter (camera, in-scene object) assisted residuals-based flicker suppression w/ location estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. User Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3A. DearPyGUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup DearPyGUI\n",
    "dpg.create_context()\n",
    "dpg.create_viewport(title='Live Braille 2', width=window_size[0], height=window_size[1])\n",
    "dpg.setup_dearpygui()\n",
    "dpg.show_viewport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texture registry\n",
    "with dpg.texture_registry(show=True): # show=True\n",
    "    dpg.add_raw_texture(width=img.shape[1], height=img.shape[0], default_value=imdpg2(img), format=dpg.mvFormat_Float_rgb, tag=\"stream_visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3B. DPG Windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dpg.window(label=\"Visualization\", tag=\"visualization_window\"):\n",
    "    dpg.add_image(\"stream_visualization\")\n",
    "dpg.set_item_pos(\"visualization_window\", (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3C. DPG Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames Per Second: 25.02\n"
     ]
    }
   ],
   "source": [
    "# %%prun -s cumulative -q -l 10 -T mainloop_profile.txt -D mainloop_profile.pstat \n",
    "\n",
    "c = 0; start_time = time.time()\n",
    "\n",
    "\n",
    "while dpg.is_dearpygui_running():\n",
    "    if debug: pass\n",
    "    else: \n",
    "        _, raw = cam.read(); raw = cv2.cvtColor(raw, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(raw, viz_res, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    result = paddle.ocr(img)\n",
    "    frame, sel = process(img, result)\n",
    "\n",
    "    dpg.set_value(\"stream_visualization\", imdpg2(frame))\n",
    "\n",
    "    dpg.render_dearpygui_frame()\n",
    "    c += 1\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "time_delta = end_time - start_time\n",
    "dpg.destroy_context()\n",
    "\n",
    "print(\"Frames Per Second:\", round(c/time_delta, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text to speech\n",
    "\n",
    "Visual description\n",
    "  - Optimization using ONNX. Someone has probably done it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed14edbca5228d46ee727e3895a84b669fc2394a68d3f600b4cef4b26033d3d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
